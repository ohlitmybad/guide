name: Translate to French

on:
  push:
    branches: [ main, master ]
    paths:
      - 'locales/xx.json'

jobs:
  translate-to-french:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout guide repo
      uses: actions/checkout@v3
      with:
        token: ${{ secrets.PAT }}
        fetch-depth: 2  # Fetch the current and previous commit

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install openai

    - name: Translate modified parts of xx.json to French
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      id: translate
      run: |
        cat > translate_to_french.py << 'EOL'
        import json
        import os
        import time
        import sys
        import difflib
        import re
        import subprocess
        from openai import OpenAI

        # Function to log with timestamps
        def log_with_time(message):
            timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
            print(f"[{timestamp}] {message}")
            sys.stdout.flush()  # Force output to be written immediately

        start_time = time.time()
        log_with_time("Starting translation process")

        # Get previous and current versions of xx.json
        log_with_time("Getting previous version of xx.json")
        try:
            # Get the hash of the previous commit
            prev_hash = subprocess.check_output(
                ['git', 'rev-parse', 'HEAD~1'],
                universal_newlines=True
            ).strip()
            
            # Get the previous version of xx.json
            prev_content = subprocess.check_output(
                ['git', 'show', f'{prev_hash}:locales/xx.json'],
                universal_newlines=True
            )
            prev_data = json.loads(prev_content)
            prev_page_content = prev_data.get('page-content', '')
            
            log_with_time("Successfully loaded previous version of xx.json")
        except Exception as e:
            log_with_time(f"Error getting previous version: {e}")
            log_with_time("Will translate the entire file as fallback")
            prev_page_content = ""

        # Load the current xx.json file
        log_with_time("Loading current xx.json file")
        with open('locales/xx.json', 'r', encoding='utf-8') as file:
            current_data = json.load(file)
            
        # Extract the current page-content
        log_with_time("Extracting current page-content")
        current_page_content = current_data.get('page-content', '')
        if not current_page_content:
            raise Exception("No 'page-content' found in xx.json")
            
        # Check if we need to translate existing fr.json
        fr_exists = os.path.exists('locales/fr.json')
        fr_data = {}
        if fr_exists:
            log_with_time("Found existing fr.json, loading it")
            with open('locales/fr.json', 'r', encoding='utf-8') as file:
                fr_data = json.load(file)
                
        # Initialize translation base (what we'll start with)
        translation_base = fr_data.get('page-content', '') if fr_exists else ''
            
        # Initialize OpenAI API
        log_with_time("Initializing OpenAI API client")
        client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        
        # Function to find HTML blocks that have changed
        def find_changed_blocks(prev_html, current_html):
            log_with_time("Finding changed HTML blocks")
            
            if not prev_html:
                log_with_time("No previous content found, will translate everything")
                return [current_html]  # If no previous content, return the entire current content
                
            # Create a diff of the HTML content
            differ = difflib.Differ()
            diff = list(differ.compare(prev_html.splitlines(), current_html.splitlines()))
            
            # Extract changed sections with context
            changed_blocks = []
            in_change_block = False
            current_block = []
            context_lines = 3  # Number of lines of context to include
            
            for i, line in enumerate(diff):
                if line.startswith('+ ') or line.startswith('- '):  # Changed line
                    if not in_change_block:
                        in_change_block = True
                        # Add context before
                        start_context = max(0, i - context_lines)
                        for j in range(start_context, i):
                            if diff[j].startswith('  '):  # Unchanged line
                                current_block.append(diff[j][2:])
                    
                    if line.startswith('+ '):  # Added line
                        current_block.append(line[2:])
                
                elif line.startswith('  '):  # Unchanged line
                    if in_change_block:
                        current_block.append(line[2:])
                        # Check if we should end the block
                        end_context_count = 0
                        for j in range(i+1, min(i+1+context_lines, len(diff))):
                            if diff[j].startswith('  '):
                                end_context_count += 1
                            else:
                                break
                        
                        if end_context_count == context_lines:
                            # We have enough unchanged context, end the block
                            changed_blocks.append('\n'.join(current_block))
                            current_block = []
                            in_change_block = False
            
            # If we're still in a change block at the end
            if in_change_block and current_block:
                changed_blocks.append('\n'.join(current_block))
            
            # If no blocks were detected, return the whole content
            if not changed_blocks:
                log_with_time("No specific changes detected, will translate everything")
                return [current_html]
                
            log_with_time(f"Found {len(changed_blocks)} changed blocks")
            return changed_blocks
        
        # Find the blocks that need to be translated
        blocks_to_translate = find_changed_blocks(prev_page_content, current_page_content)
        
        # Function to translate a block
        def translate_block(block, block_index, total_blocks):
            log_with_time(f"Translating block {block_index+1}/{total_blocks} ({len(block)} characters)")
            
            translation_start = time.time()
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Translate the given HTML content into French while keeping all HTML tags and structure intact. Use widely accepted French football terminology. Maintain authenticity and precision without altering the original meaning. Output only the translations without any additional text or markdown."},
                    {"role": "user", "content": block}
                ],
                temperature=0.7,
            )
            translation_end = time.time()
            
            log_with_time(f"Block {block_index+1} translated in {(translation_end - translation_start):.2f} seconds")
            
            translated_block = response.choices[0].message.content
            if translated_block.startswith("```") and translated_block.endswith("```"):
                translated_block = re.sub(r'^```.*\n', '', translated_block)
                translated_block = re.sub(r'\n```$', '', translated_block)
                
            return translated_block
        
        # Update the fr.json file
        if len(blocks_to_translate) == 1 and blocks_to_translate[0] == current_page_content:
            # If we're translating the entire content
            log_with_time("Translating the entire page content")
            if len(current_page_content) > 6000:
                # Process large content in chunks as in the original script
                # (Code for chunking large content would go here, similar to the original)
                # ...
                log_with_time("Content is large, processing in batches")
                
                # Split content into manageable chunks based on HTML structure
                chunks = []
                current_position = 0
                
                # Function to find a good split point
                def find_split_point(text, start_pos, chunk_size=6000):
                    end_pos = min(start_pos + chunk_size, len(text))
                    if end_pos >= len(text):
                        return len(text)
                    
                    # Look for end of section/div tags as good split points
                    for marker in ['</section>', '</div>']:
                        marker_pos = text.rfind(marker, start_pos, end_pos)
                        if marker_pos != -1:
                            return marker_pos + len(marker)
                    
                    # If no good split point found, look for end of paragraph
                    paragraph_end = text.rfind('</p>', start_pos, end_pos)
                    if paragraph_end != -1:
                        return paragraph_end + 4
                    
                    # Fallback to sentence end
                    for punct in ['. ', '! ', '? ']:
                        punct_pos = text.rfind(punct, start_pos, end_pos)
                        if punct_pos != -1:
                            return punct_pos + 2
                    
                    # Last resort: just split at chunk_size
                    return end_pos
                
                # Split content into chunks
                while current_position < len(current_page_content):
                    split_point = find_split_point(current_page_content, current_position)
                    chunk = current_page_content[current_position:split_point]
                    chunks.append(chunk)
                    current_position = split_point
                
                log_with_time(f"Split content into {len(chunks)} chunks")
                
                # Translate each chunk separately
                translated_chunks = []
                for i, chunk in enumerate(chunks):
                    translated_chunk = translate_block(chunk, i, len(chunks))
                    translated_chunks.append(translated_chunk)
                
                # Combine all translated chunks
                log_with_time("Combining all translated chunks")
                translated_content = "".join(translated_chunks)
            else:
                # Translate the whole content at once
                translated_content = translate_block(current_page_content, 0, 1)
        else:
            # If we're translating specific blocks
            log_with_time(f"Translating {len(blocks_to_translate)} modified blocks")
            
            # Start with the current translation if available
            if translation_base:
                log_with_time("Using existing French translation as base")
                translated_content = translation_base
            else:
                # If no existing translation, translate everything
                log_with_time("No existing translation found, translating everything")
                translated_content = translate_block(current_page_content, 0, 1)
                
            # Translate each modified block and update the content
            for i, block in enumerate(blocks_to_translate):
                if translation_base:  # Only attempt to replace if we have a base translation
                    translated_block = translate_block(block, i, len(blocks_to_translate))
                    
                    # Find where this block should go in the original content
                    block_start = current_page_content.find(block)
                    if block_start != -1:
                        log_with_time(f"Found position of block {i+1} in original content")
                        
                        # Instead of a simple ratio-based approach, which can cause misalignment,
                        # let's try to find unique HTML markers around the changed block to locate
                        # the correct position in the translated content
                        
                        # Extract a few lines before and after the block as "anchors"
                        context_before = current_page_content[max(0, block_start-200):block_start]
                        context_after = current_page_content[block_start+len(block):min(len(current_page_content), block_start+len(block)+200)]
                        
                        # Find unique HTML patterns in the context (like tags with specific ids or classes)
                        def extract_unique_pattern(text, min_length=15):
                            # Look for tag patterns that are likely unique
                            patterns = re.findall(r'<[^>]+id="[^"]+"[^>]*>', text)
                            if not patterns:
                                patterns = re.findall(r'<[^>]+class="[^"]+"[^>]*>', text)
                            if not patterns:
                                # If no ID/class tags found, try other unique patterns
                                patterns = re.findall(r'<h\d>[^<]{5,}</h\d>', text)
                            if not patterns:
                                # Fall back to any HTML tag with content
                                patterns = re.findall(r'<[a-z1-6]+>[^<]{5,}</[a-z1-6]+>', text)
                                
                            # Filter for patterns that are likely unique
                            unique_patterns = [p for p in patterns if len(p) >= min_length]
                            return unique_patterns[0] if unique_patterns else None
                        
                        # If the block is very small (like just a date change), get more context
                        if len(block) < 50:
                            log_with_time(f"Block {i+1} is very small, getting more context for accurate positioning")
                            # Get more context before and after
                            more_context_before = current_page_content[max(0, block_start-500):block_start]
                            more_context_after = current_page_content[block_start+len(block):min(len(current_page_content), block_start+len(block)+500)]
                            
                            # Look for complete HTML elements or sections
                            # Find the nearest opening tag before the block
                            tag_before_match = re.search(r'<([a-z][a-z0-9]*)[^>]*>(?:[^<]|<(?!/\1))*$', more_context_before)
                            # Find the nearest closing tag after the block
                            tag_after_match = re.search(r'^(?:[^>]|<(?!/[a-z]))*</([a-z][a-z0-9]*)>', more_context_after)
                            
                            if tag_before_match and tag_after_match and tag_before_match.group(1) == tag_after_match.group(1):
                                # We found matching tags enclosing our small change
                                tag_name = tag_before_match.group(1)
                                log_with_time(f"Found enclosing {tag_name} tags for the small change")
                                
                                # Find the complete element in the original content
                                element_pattern = more_context_before[tag_before_match.start():] + block + more_context_after[:tag_after_match.end()]
                                
                                # Find this element in the translated content
                                # First try exact structure matching
                                element_structure = re.sub(r'>([^<]+)<', '><', element_pattern)  # Remove text between tags to match structure
                                translated_structure = re.sub(r'>([^<]+)<', '><', translation_base)
                                
                                structure_pos = translated_structure.find(element_structure)
                                if structure_pos != -1:
                                    # Found matching structure, now extract the corresponding full element from translation
                                    translated_element_match = re.search(element_structure, translated_structure)
                                    if translated_element_match:
                                        element_start = translated_structure.find(translated_element_match.group(0))
                                        element_end = element_start + len(translated_element_match.group(0))
                                        
                                        # Now, only translate the small change, not the entire element
                                        # Find the exact position of the small change within the element
                                        relative_change_pos = element_pattern.find(block)
                                        if relative_change_pos != -1:
                                            # Translate just the small part that changed
                                            small_part_translated = translate_block(block, i, len(blocks_to_translate))
                                            
                                            # Update just that small part in the translated content
                                            translated_content = translation_base[:element_start+relative_change_pos] + small_part_translated + translation_base[element_start+relative_change_pos+len(block):]
                                            log_with_time(f"Successfully updated just the small changed part in block {i+1}")
                                            continue
                        
                        # If we couldn't do precise small change replacement, fall back to pattern matching
                        before_pattern = extract_unique_pattern(context_before)
                        after_pattern = extract_unique_pattern(context_after)
                        
                        if before_pattern and after_pattern:
                            # Try to find these patterns in the translated content
                            before_pos = translation_base.find(before_pattern)
                            after_pos = translation_base.find(after_pattern, before_pos if before_pos != -1 else 0)
                            
                            if before_pos != -1 and after_pos != -1:
                                # We found good anchor points in the translated content
                                log_with_time(f"Found anchor points for block {i+1} in translated content")
                                
                                # Extract the corresponding block in the translated content
                                corresponding_block = translation_base[before_pos + len(before_pattern):after_pos]
                                
                                # Replace just that block with the new translation
                                translated_content = translation_base[:before_pos + len(before_pattern)] + translated_block + translation_base[after_pos:]
                                log_with_time(f"Updated translated content with precise positioning for block {i+1}")
                                continue
                        
                        # Fallback to the ratio-based approach if we couldn't find good patterns
                        log_with_time(f"Couldn't find precise anchors for block {i+1}, using ratio-based approach")
                        # Find the corresponding position in the translated content
                        ratio = len(translated_content) / len(current_page_content)
                        estimated_pos = int(block_start * ratio)
                        
                        # Apply the translation with a margin around it to avoid cutting in the middle of HTML tags
                        # This is still a fallback approach
                        safe_start = max(0, estimated_pos - 10)
                        safe_end = min(len(translated_content), estimated_pos + len(block) * ratio + 10)
                        
                        # Look for tag boundaries for safer replacement
                        tag_start = translated_content.rfind('>', safe_start, estimated_pos)
                        tag_end = translated_content.find('<', estimated_pos, safe_end)
                        
                        if tag_start != -1 and tag_end != -1:
                            log_with_time(f"Found tag boundaries for safer replacement in block {i+1}")
                            translated_content = translated_content[:tag_start+1] + translated_block + translated_content[tag_end:]
                        else:
                            # Last resort - direct replacement at estimated position
                            log_with_time(f"Updating translated content at estimated position for block {i+1}")
                            translated_content = translated_content[:estimated_pos] + translated_block + translated_content[estimated_pos + int(len(block) * ratio):]
        
        # Create the fr.json file
        log_with_time("Creating fr.json file")
        fr_data = {
            "common": {"nav": {"players": "Joueurs","pro": "Pro","teams": "Équipes"}},
            "meta": {"title": "DataMB | Guide","description": "Explication des outils, des statistiques et de la méthodologie utilisés par DataMB"},
            "search": {"placeholder": "Cherchez une équipe ou joueur..."},
            "page-content": translated_content
        }
        
        os.makedirs('locales', exist_ok=True)
        with open('locales/fr.json', 'w', encoding='utf-8') as json_file:
            json.dump(fr_data, json_file, ensure_ascii=False, indent=2)

        total_time = time.time() - start_time
        log_with_time(f"Translated content saved to locales/fr.json. Total execution time: {total_time:.2f} seconds")
        EOL

        python translate_to_french.py

    - name: Commit and push French translation
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add locales/fr.json
        git diff --quiet && git diff --staged --quiet || git commit -m "Auto-translate xx.json to French"
        git push

    - name: Checkout proguide repo
      uses: actions/checkout@v3
      with:
        repository: ohlitmybad/proguide
        path: proguide
        token: ${{ secrets.PAT }}

    - name: Commit and push proguide changes
      run: |
        cd proguide
        mkdir -p locales
        cp $GITHUB_WORKSPACE/locales/fr.json locales/
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add index.html locales/fr.json
        git diff --quiet && git diff --staged --quiet || git commit -m "Auto-translate xx.json to French"
        git push
